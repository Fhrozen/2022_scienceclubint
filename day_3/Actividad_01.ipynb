{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645cb88e",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac0e47",
   "metadata": {},
   "source": [
    "In this notebook, we will train models with deep learning\n",
    "En este ultimo notebook, realizaremos ejercicios acerca del aprendizaje profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2cda80",
   "metadata": {},
   "source": [
    "First, we import the PyTorch library (torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812edd2e",
   "metadata": {},
   "source": [
    "Refs:\n",
    "- https://pytorch.org/docs/stable/torch.html\n",
    "- https://deeplearning.neuromatch.io/tutorials/intro.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8867d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f25008",
   "metadata": {},
   "source": [
    "## Linear Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4aa29",
   "metadata": {},
   "source": [
    "The linear layers perform a linear transformation: $y = xW^T+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061dcd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da03cde",
   "metadata": {},
   "source": [
    "## Convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a312e",
   "metadata": {},
   "source": [
    "The convolutional layers perform a linear transformation appling an array to the input.\n",
    "This array (weights) has fewer dimensions than the input.\n",
    "This architecture has shared weights and is named **invariant field** or **invariant space**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ae6c7",
   "metadata": {},
   "source": [
    "They are used for images (3-D arrays), and are named 2-D convolutions.\n",
    "It is possible to find 1-D and N-D.\n",
    "For a 2-D convolution, the output of the layer is formulated as following:\n",
    "\n",
    "$ out(N_i, C_{out_j}) = bias(C_{out_j}) + \\sum_{k=0}^{C_{in}-1}{weight(C_{out_j}, k) * input(N_i, k)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c53632",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3076dc50",
   "metadata": {},
   "source": [
    "![](conv2d.gif)\n",
    "\n",
    "Refs: https://ai.plainenglish.io/building-and-training-a-convolutional-neural-network-cnn-from-scratch-9a64bcc62c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f9d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d5ac2af",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a2d48",
   "metadata": {},
   "source": [
    "Ref:\n",
    "- https://www.sciencedirect.com/topics/engineering/nonlinearities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f597ac05",
   "metadata": {},
   "source": [
    "The activation functions express a non-linear relationship between the independent variable (input) and the dependent one (output).\n",
    "\n",
    "Functions:  \n",
    "  $y = sigmoid(x)$  \n",
    "  $y = tanh(x)$  \n",
    "  $y = softmax(x)$  \n",
    "\n",
    "Now, initialize a vector x with values between -10 and 10 and apply each function. Plot the output.\n",
    "Ahora, define una vector x desde -10 hasta 10, y aplica la funcion. Grafica la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e04d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0403cd26",
   "metadata": {},
   "source": [
    "# Training Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b25344",
   "metadata": {},
   "source": [
    "### Setting the training device\n",
    "\n",
    "Using a GPU for training will speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d2f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32afcc5b",
   "metadata": {},
   "source": [
    "## Loading a database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190be53",
   "metadata": {},
   "source": [
    "We will use the MNIST and CIFAR data sets for image classification.\n",
    "\n",
    "Ref:\n",
    "- https://pytorch.org/vision/stable/datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ec9ce",
   "metadata": {},
   "source": [
    "Lets employ `torchvision.datasets.`  \n",
    "After loading, lets show an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a95866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = \n",
    "test_set = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec43e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6c2d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5af250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': 16}\n",
    "test_kwargs = {'batch_size': 16}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True,\n",
    "                   'shuffle': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b85fe",
   "metadata": {},
   "source": [
    "## Designing a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b01609",
   "metadata": {},
   "source": [
    "Lets design a basic model using the `nn.Module` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37465ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, idim, odim):\n",
    "        super().__init__()\n",
    "        self.capa1 = \n",
    "        self.capa2 = \n",
    "    \n",
    "    def forward(self, tensor_x):\n",
    "        return tensor_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58826deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd0993",
   "metadata": {},
   "source": [
    "## Setting the training rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481fb837",
   "metadata": {},
   "source": [
    "We import the optimizers to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = \n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c901ee6",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd848ff",
   "metadata": {},
   "source": [
    "Lets setup the training routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ce0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf827fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = \n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(args, model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d0b75",
   "metadata": {},
   "source": [
    "You can now save your model with:\n",
    "```python\n",
    "torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fe494d",
   "metadata": {},
   "source": [
    "## Now, you.\n",
    "\n",
    "Perform the same process (from the data loading up to the training), using the CIFAR10 data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca3614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c9f745",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ad0d2a",
   "metadata": {},
   "source": [
    "Use the model trained with MNIST and finetune it for CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c6478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d097687b",
   "metadata": {},
   "source": [
    "# Recurrent layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a9b7c0",
   "metadata": {},
   "source": [
    "![](rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d335e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96b78087",
   "metadata": {},
   "source": [
    "# Attention layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be71d5e",
   "metadata": {},
   "source": [
    "![](attn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bc563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01822139",
   "metadata": {},
   "source": [
    "# Semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92260a",
   "metadata": {},
   "source": [
    "![](semi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb50711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e37ad8",
   "metadata": {},
   "source": [
    "# Self-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973bdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a8089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf1fc2fa",
   "metadata": {},
   "source": [
    "# Knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672dc21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "551e9becf8fe707a6e42af77a66725df66af1e35803eb56e993681e98828e3c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
